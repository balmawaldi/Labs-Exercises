{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8614dd9b",
   "metadata": {},
   "source": [
    "# Lab 4: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e7333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import html5lib\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198f5d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>Learn Web Scraping | Scrape This Site | A public sandbox for learning web scraping</title>\n",
      "<link href=\"/static/images/scraper-icon.png\" rel=\"icon\" type=\"image/png\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<meta content=\"Here are some practice pages you can scrape.\" name=\"description\"/>\n",
      "<link crossorigin=\"anonymous\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css\" integrity=\"sha256-MfvZlkHCEqatNoGiOXveE8FIwMzZg4W85qfrfIFBfYc= sha512-dTfge/zgoMYpP7QbHy4gWMEGsbsdZeCXz7irItjcC3sPUFtf0kuFbDz/ixG7ArTxmDjLXDmezHubeNikyKGVyQ==\" rel=\"stylesheet\"/>\n",
      "<link href=\"https://fonts.googleapis.com/css?family=Lato:400,700\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<link href=\"/static/css/styles.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "</head>\n",
      "<body>\n",
      "<nav id=\"site-nav\">\n",
      "<div class=\"container\">\n",
      "<div class=\"col-md-12\">\n",
      "<ul class=\"nav nav-tabs\">\n",
      "<li id=\"nav-homepage\">\n",
      "<a class=\"nav-link hidden-sm hidden-xs\" href=\"/\">\n",
      "<img id=\"nav-logo\" src=\"/static/images/scraper-icon.png\"/>\n",
      "                                Scrape This Site\n",
      "                            </a>\n",
      "</li>\n",
      "<li id=\"nav-sandbox\">\n",
      "<a class=\"nav-link\" href=\"/pages/\">\n",
      "<i class=\"glyphicon glyphicon-console hidden-sm hidden-xs\"></i>\n",
      "                                Sandbox\n",
      "                            </a>\n",
      "</li>\n",
      "<li id=\"nav-lessons\">\n",
      "<a class=\"nav-link\" href=\"/lessons/\">\n",
      "<i class=\"glyphicon glyphicon-education hidden-sm hidden-xs\"></i>\n",
      "                                Lessons\n",
      "                            </a>\n",
      "</li>\n",
      "<li id=\"nav-faq\">\n",
      "<a class=\"nav-link\" href=\"/faq/\">\n",
      "<i class=\"glyphicon glyphicon-flag hidden-sm hidden-xs\"></i>\n",
      "                                FAQ\n",
      "                            </a>\n",
      "</li>\n",
      "<li class=\"pull-right\" id=\"nav-login\">\n",
      "<a class=\"nav-link\" href=\"/login/\">\n",
      "                                Login\n",
      "                            </a>\n",
      "</li>\n",
      "</ul>\n",
      "</div>\n",
      "</div>\n",
      "</nav>\n",
      "<script type=\"text/javascript\">\n",
      "            var path = document.location.pathname;\n",
      "            var tab = undefined;\n",
      "            if (path === \"/\"){\n",
      "                tab = document.querySelector(\"#nav-homepage\");\n",
      "            } else if (path.indexOf(\"/faq/\") === 0){\n",
      "                tab = document.querySelector(\"#nav-faq\");\n",
      "            } else if (path.indexOf(\"/lessons/\") === 0){\n",
      "                tab = document.querySelector(\"#nav-lessons\");\n",
      "            } else if (path.indexOf(\"/pages/\") === 0) {\n",
      "                tab = document.querySelector(\"#nav-sandbox\");\n",
      "            } else if (path.indexOf(\"/login/\") === 0) {\n",
      "                tab = document.querySelector(\"#nav-login\");\n",
      "            }\n",
      "            tab.classList.add(\"active\")\n",
      "        </script>\n",
      "<div id=\"pages\">\n",
      "<section>\n",
      "<div class=\"container\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-6 col-md-offset-3\">\n",
      "<h1>Web Scraping Sandbox</h1>\n",
      "<hr/>\n",
      "<div class=\"page\">\n",
      "<h3 class=\"page-title\">\n",
      "<a href=\"/pages/simple/\">Countries of the World: A Simple Example</a>\n",
      "</h3>\n",
      "<p class=\"lead session-desc\">\n",
      "                                A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\n",
      "                            </p>\n",
      "<hr/>\n",
      "</div><!--.page-->\n",
      "<div class=\"page\">\n",
      "<h3 class=\"page-title\">\n",
      "<a href=\"/pages/forms/\">Hockey Teams: Forms, Searching and Pagination</a>\n",
      "</h3>\n",
      "<p class=\"lead session-desc\">\n",
      "                                Browse through a database of NHL team stats since 1990. Practice building a scraper that handles common website interface components.\n",
      "                            </p>\n",
      "<hr/>\n",
      "</div><!--.page-->\n",
      "<div class=\"page\">\n",
      "<h3 class=\"page-title\">\n",
      "<a href=\"/pages/ajax-javascript/\">Oscar Winning Films: AJAX and Javascript</a>\n",
      "</h3>\n",
      "<p class=\"lead session-desc\">\n",
      "                                Click through a bunch of great films. Learn how content is added to the page asynchronously with Javascript and how you can scrape it.\n",
      "                            </p>\n",
      "<hr/>\n",
      "</div><!--.page-->\n",
      "<div class=\"page\">\n",
      "<h3 class=\"page-title\">\n",
      "<a href=\"/pages/frames/\">Turtles All the Way Down: Frames &amp; iFrames</a>\n",
      "</h3>\n",
      "<p class=\"lead session-desc\">\n",
      "                                Some older sites might still use frames to break up thier pages. Modern ones might be using iFrames to expose data. Learn about turtles as you scrape content inside frames.\n",
      "                            </p>\n",
      "<hr/>\n",
      "</div><!--.page-->\n",
      "<div class=\"page\">\n",
      "<h3 class=\"page-title\">\n",
      "<a href=\"/pages/advanced/\">Advanced Topics: Real World Challenges You'll Encounter</a>\n",
      "</h3>\n",
      "<p class=\"lead session-desc\">\n",
      "                                Scraping real websites, you're likely run into a number of common gotchas. Get practice with spoofing headers, handling logins &amp; session cookies, finding CSRF tokens, and other common network errors.\n",
      "                            </p>\n",
      "<hr/>\n",
      "</div><!--.page-->\n",
      "</div><!--.col-->\n",
      "</div><!--.row-->\n",
      "</div><!--.container-->\n",
      "</section>\n",
      "</div>\n",
      "<section id=\"footer\">\n",
      "<div class=\"container\">\n",
      "<div class=\"row\">\n",
      "<div class=\"col-md-12 text-center text-muted\">\n",
      "                    Lessons and Videos © Hartley Brody 2023\n",
      "                </div><!--.col-->\n",
      "</div><!--.row-->\n",
      "</div><!--.container-->\n",
      "</section>\n",
      "</body>\n",
      "<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js\"></script>\n",
      "<script crossorigin=\"anonymous\" integrity=\"sha256-Sk3nkD6mLTMOF0EOpNtsIry+s1CsaqQC1rVLTAy+0yc= sha512-K1qjQ+NcF2TYO/eI3M6v8EiNYZfA95pQumfvcVrTHtwQVDG+aHRqLi/ETn2uB+1JqwYqVG3LIvdm9lj6imS/pQ==\" src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js\"></script>\n",
      "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/pnotify/2.1.0/pnotify.core.min.js\"></script>\n",
      "<link href=\"https://cdnjs.cloudflare.com/ajax/libs/pnotify/2.1.0/pnotify.core.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<!-- pnotify messages -->\n",
      "<script type=\"text/javascript\">\n",
      "    \n",
      "    PNotify.prototype.options.styling = \"bootstrap3\";\n",
      "    $(function(){\n",
      "      \n",
      "    });\n",
      "    \n",
      "\n",
      "    $(function () {\n",
      "      $('[data-toggle=\"tooltip\"]').tooltip()\n",
      "    })\n",
      "  </script>\n",
      "<!-- golbal video controls -->\n",
      "<script type=\"text/javascript\">\n",
      "    $(\"video\").hover(function() {\n",
      "        $(this).prop(\"controls\", true);\n",
      "    }, function() {\n",
      "        $(this).prop(\"controls\", false);\n",
      "    });\n",
      "\n",
      "    $(\"video\").click(function() {\n",
      "        if( this.paused){\n",
      "            this.play();\n",
      "        }\n",
      "        else {\n",
      "            this.pause();\n",
      "        }\n",
      "    });\n",
      "    </script>\n",
      "<!-- insert google analytics here -->\n",
      "<script>\n",
      "    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n",
      "    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n",
      "    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n",
      "    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n",
      "\n",
      "    ga('create', 'UA-41551755-8', 'auto');\n",
      "    ga('send', 'pageview');\n",
      "  </script>\n",
      "<!-- Facebook Pixel Code -->\n",
      "<script>\n",
      "  !function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod?\n",
      "  n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n;\n",
      "  n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;\n",
      "  t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,\n",
      "  document,'script','https://connect.facebook.net/en_US/fbevents.js');\n",
      "\n",
      "  fbq('init', '764287443701341');\n",
      "  fbq('track', \"PageView\");</script>\n",
      "<noscript><img height=\"1\" src=\"https://www.facebook.com/tr?id=764287443701341&amp;ev=PageView&amp;noscript=1\" style=\"display:none\" width=\"1\"/></noscript>\n",
      "<!-- End Facebook Pixel Code -->\n",
      "<!-- Google Code for Remarketing Tag -->\n",
      "<script type=\"text/javascript\">\n",
      "    /* <![CDATA[ */\n",
      "    var google_conversion_id = 950945448;\n",
      "    var google_custom_params = window.google_tag_params;\n",
      "    var google_remarketing_only = true;\n",
      "    /* ]]> */\n",
      "    </script>\n",
      "<script src=\"//www.googleadservices.com/pagead/conversion.js\" type=\"text/javascript\">\n",
      "</script>\n",
      "<noscript>\n",
      "<div style=\"display:inline;\">\n",
      "<img alt=\"\" height=\"1\" src=\"//googleads.g.doubleclick.net/pagead/viewthroughconversion/950945448/?guid=ON&amp;script=0\" style=\"border-style:none;\" width=\"1\"/>\n",
      "</div>\n",
      "</noscript>\n",
      "<!-- Global site tag (gtag.js) - Google AdWords: 950945448 -->\n",
      "<script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=AW-950945448\"></script>\n",
      "<script>\n",
      "   window.dataLayer = window.dataLayer || [];\n",
      "   function gtag(){dataLayer.push(arguments);}\n",
      "   gtag('js', new Date());\n",
      "\n",
      "   gtag('config', 'AW-950945448');\n",
      "  </script>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "source = requests.get(\"https://www.scrapethissite.com/pages/\").text\n",
    "soup = BeautifulSoup(source, \"lxml\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a3a88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"page\">\n",
      " <h3 class=\"page-title\">\n",
      "  <a href=\"/pages/simple/\">\n",
      "   Countries of the World: A Simple Example\n",
      "  </a>\n",
      " </h3>\n",
      " <p class=\"lead session-desc\">\n",
      "  A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\n",
      " </p>\n",
      " <hr/>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "section = soup.find(\"div\", class_= \"page\") #isolating div & the class\n",
    "print(section.prettify()) #prettify makes it easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6dffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3 class=\"page-title\">\n",
      " <a href=\"/pages/simple/\">\n",
      "  Countries of the World: A Simple Example\n",
      " </a>\n",
      "</h3>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heading = soup.find(\"h3\", class_= \"page-title\")\n",
    "print(heading.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1ce656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries of the World: A Simple Example\n",
      "\n",
      "                                A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\n",
      "                            \n"
     ]
    }
   ],
   "source": [
    "title = section.h3.a.text\n",
    "p_text = section.find(\"p\", class_=\"lead session-desc\").text\n",
    "print(title)\n",
    "print(p_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc80aa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries of the World: A Simple Example\n",
      "A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\n",
      "Hockey Teams: Forms, Searching and Pagination\n",
      "Browse through a database of NHL team stats since 1990. Practice building a scraper that handles common website interface components.\n",
      "Oscar Winning Films: AJAX and Javascript\n",
      "Click through a bunch of great films. Learn how content is added to the page asynchronously with Javascript and how you can scrape it.\n",
      "Turtles All the Way Down: Frames & iFrames\n",
      "Some older sites might still use frames to break up thier pages. Modern ones might be using iFrames to expose data. Learn about turtles as you scrape content inside frames.\n",
      "Advanced Topics: Real World Challenges You'll Encounter\n",
      "Scraping real websites, you're likely run into a number of common gotchas. Get practice with spoofing headers, handling logins & session cookies, finding CSRF tokens, and other common network errors.\n"
     ]
    }
   ],
   "source": [
    "for element in soup.find_all(\"div\", class_= \"page\"):\n",
    "    \n",
    "    title = element.h3.a.text.strip()\n",
    "    print(title)\n",
    "    \n",
    "    text = element.find(\"p\", class_=\"lead session-desc\").text.strip()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e4d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries of the World: A Simple Example\n",
      "A single page that lists information about all the countries in the world. Good for those just get started with web scraping.\n",
      "Hockey Teams: Forms, Searching and Pagination\n",
      "Browse through a database of NHL team stats since 1990. Practice building a scraper that handles common website interface components.\n",
      "Oscar Winning Films: AJAX and Javascript\n",
      "Click through a bunch of great films. Learn how content is added to the page asynchronously with Javascript and how you can scrape it.\n",
      "Turtles All the Way Down: Frames & iFrames\n",
      "Some older sites might still use frames to break up thier pages. Modern ones might be using iFrames to expose data. Learn about turtles as you scrape content inside frames.\n",
      "Advanced Topics: Real World Challenges You'll Encounter\n",
      "Scraping real websites, you're likely run into a number of common gotchas. Get practice with spoofing headers, handling logins & session cookies, finding CSRF tokens, and other common network errors.\n"
     ]
    }
   ],
   "source": [
    "source = requests.get(\"https://www.scrapethissite.com/pages/\").text\n",
    "soup = BeautifulSoup(source, \"lxml\")\n",
    "\n",
    "csv_file = open(\"cms_scrape.csv\", \"w\", newline = \"\", encoding = \"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"headline\", \"summary\"])\n",
    "\n",
    "for element in soup.find_all(\"div\", class_= \"page\"):\n",
    "    \n",
    "    title = element.h3.a.text.strip()\n",
    "    print(title)\n",
    "    \n",
    "    text = element.find(\"p\", class_=\"lead session-desc\").text.strip()\n",
    "    print(text)\n",
    "    \n",
    "    csv_writer.writerow([title, text])\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216bebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"col-md-4 country\">\n",
      " <h3 class=\"country-name\">\n",
      "  <i class=\"flag-icon flag-icon-ad\">\n",
      "  </i>\n",
      "  Andorra\n",
      " </h3>\n",
      " <div class=\"country-info\">\n",
      "  <strong>\n",
      "   Capital:\n",
      "  </strong>\n",
      "  <span class=\"country-capital\">\n",
      "   Andorra la Vella\n",
      "  </span>\n",
      "  <br/>\n",
      "  <strong>\n",
      "   Population:\n",
      "  </strong>\n",
      "  <span class=\"country-population\">\n",
      "   84000\n",
      "  </span>\n",
      "  <br/>\n",
      "  <strong>\n",
      "   Area (km\n",
      "   <sup>\n",
      "    2\n",
      "   </sup>\n",
      "   ):\n",
      "  </strong>\n",
      "  <span class=\"country-area\">\n",
      "   468.0\n",
      "  </span>\n",
      "  <br/>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source_con = requests.get(\"https://www.scrapethissite.com/pages/simple/\").text\n",
    "soup_con = BeautifulSoup(source_con, \"lxml\")\n",
    "section_con = soup_con.find(\"div\", class_= \"col-md-4 country\") \n",
    "print(section_con.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b9c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_con = requests.get(\"https://www.scrapethissite.com/pages/simple/\").text\n",
    "soup_con = BeautifulSoup(source_con, \"lxml\")\n",
    "\n",
    "\n",
    "csv_file = open(\"country_scrape.csv\", \"w\", newline = \"\", encoding = \"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"country\", \"summary\"])\n",
    "\n",
    "for element in soup_con.find_all(\"div\", class_= \"col-md-4 country\"):\n",
    "    \n",
    "    title_con = element.find(\"h3\", class_=\"country-name\").text.strip()\n",
    "    text_con = element.find(\"div\", class_=\"country-info\").text.strip()\n",
    "    csv_writer.writerow([title_con, text_con])\n",
    "    \n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef87056",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "num = 1\n",
    "\n",
    "while page != 4:\n",
    "    books = requests.get(f\"https://books.toscrape.com/catalogue/page-{page}.html\").text\n",
    "    soup = BeautifulSoup(books, \"lxml\")\n",
    "    \n",
    "    for element in soup.find_all(\"article\", class_= \"product-pod\"):\n",
    "        title = element.h3.a.text\n",
    "        price = element.find(\"p\", class_=\"price-color\").text.strip(\"Â\")\n",
    "        \n",
    "        print(f\"{num}. {title} -- {price}\")\n",
    "        num += 1\n",
    "    \n",
    "    page += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2dd2e",
   "metadata": {},
   "source": [
    "# Post Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362d7eb",
   "metadata": {},
   "source": [
    "- Scrape this IMDB website of the top 100 movies \n",
    "  - Isolate the title, the date of release, and one other element of your choosing. (3pts) Put the data into a csv. (2pts)\n",
    "- Scrape this Library of Congress search \n",
    "  - Scrape the first 5 pages, grab the title, item description, and webpage hyperlink. (3pts) Put the data into a csv. (2pts)\n",
    "  - Bonus 2pts: figure out how to isolate the contributor name & item date (*updated bonus as I had originally read HTML incorrectly – Dr. G)\n",
    "- Upload your code & csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "516820c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB Scrape\n",
    "source1 = requests.get(\"https://www.imdb.com/list/ls055592025/\").text\n",
    "movie = BeautifulSoup(source1, \"lxml\")\n",
    "\n",
    "csv_file = open(\"imdb_top100\", \"w\", newline = \"\", encoding = \"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Title\", \"Year\", \"Genre\"])\n",
    "\n",
    "for element in movie.find_all(\"div\", class_= \"lister-item-content\"):\n",
    "    \n",
    "    title = element.h3.a.text\n",
    "    year = element.find(\"span\", class_= \"lister-item-year text-muted unbold\").text.strip()\n",
    "    genre = element.find(\"span\", class_= \"genre\").text.strip()\n",
    "    csv_writer.writerow([title, year, genre])  \n",
    "\n",
    "csv_file.close()\n",
    "#extra element chosen: genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e850e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOC Scrape\n",
    "source2 = requests.get(\"https://www.loc.gov/search/?q=cats&sp=1\").text\n",
    "loc = BeautifulSoup(source2, \"lxml\")\n",
    "csv_file = open(\"LOC_Cats\", \"w\", newline = \"\", encoding = \"utf-8\")\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\"Title\", \"Item Description\", \"Hyperlink\", \"Contributor\", \"Date\"])\n",
    "\n",
    "page = 1\n",
    "num = 1\n",
    "\n",
    "while page != 6:\n",
    "    source2 = requests.get(f\"https://www.loc.gov/search/?q=cats&sp={page}\").text\n",
    "    loc = BeautifulSoup(source2, \"lxml\")\n",
    "    loc_links = BeautifulSoup(source2, \"html.parser\")\n",
    "    \n",
    "    for element in loc.find_all(\"div\", class_= \"description\"):\n",
    "        title = element.find(\"span\", class_= \"item-description-title\").text.strip()\n",
    "        data = element.find(\"a\", href = True)\n",
    "        link = data.get('href')  \n",
    "        try:\n",
    "            descript = element.find(\"span\", class_= \"item-description-abstract\").text.strip()\n",
    "        except AttributeError:\n",
    "            descript = \"No Data\"\n",
    "        try:\n",
    "            contri = element.find(\"li\", class_= \"contributor\").text.strip()         \n",
    "        except AttributeError:\n",
    "            contri = \"No Data\"\n",
    "        try:\n",
    "            date = element.find(\"li\", class_=\"date\").text.strip()         \n",
    "        except AttributeError:\n",
    "            date = \"No Data\"\n",
    "        csv_writer.writerow([title, descript, link, contri, date])\n",
    "        num += 1\n",
    "    \n",
    "    page += 1 \n",
    "    \n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
